\documentclass[10pt]{../sigplanconf}

\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{semantic}

\conferenceinfo{DIKU workshop on Topics in Programming Languages,}{June 2011.}
\title{To Trim a Perfect Process Tree}
%\subtitle{Subtitle Text, if any}
\authorinfo{Martin Dybdal}
           {dybber@dybber.dk}
           {DIKU, Department of Computer Science, University of Copenhagen}
\authorinfo{Ulrik Rasmussen}
           {dolle@diku.dk}
           {DIKU, Department of Computer Science, University of Copenhagen}
\authorpermission
\copyrightdata{draft}

\mathlig{::=}{\quad ::=\quad}
\mathlig{|->}{\mapsto}
\mathlig{<|}{\trianglelefteq}
\mathlig{<<}{\langle}
\mathlig{>>}{\rangle}
\newcommand{\dom}{\ensuremath{{\rm dom}}}

% For proofs, As frac but does not change the font size
\newcommand{\nfrac}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}
% Small-caps tags
\newcommand{\tagsc}[1]{\tag{\scshape #1}}

\begin{document}
\maketitle

\begin{abstract}
  The Universal Resolving Algorithm\cite{abramov2000universal} is an
  algorithm for inverse interpretation, based on the notion of a
  perfect process tree for representing the possible traces of a
  program. A process tree will often have an infinite representation,
  meaning that inverse interpretation does not always terminate.

  We investigate two methods for minimizing the size of a process tree
  and representing it in finite form, respectively.

  Generation of process trees by driving is a technique that
  originates from the field of
  supercompilation\cite{sorensen1998introduction}. A positive
  supercompiler uses a technique called \emph{generalization} to
  ensure that it will eventually arrive at a process tree with a
  finite representation, which still represents all possible
  configurations of the program. To our knowledge, the same technique
  has not been applied to the field of inverse interpretation.
\end{abstract}

\keywords Inverse Interpretation, Generalization, Universal Resolving
Algorithm.
\begin{center}
  \vspace{0.5cm}
  \includegraphics[width=0.6\columnwidth]{../figures/pruning.pdf}
  \vspace{0.5cm}
\end{center}

\newpage
\section{Introduction}
Conventionally, when we execute a program, we hand it some an input
value and after some time it returns with an output. In the field of
\textit{inverse interpretation}, we seek to reverse this process, by
handing the same program its output and then finding the possible
inputs by ``backwards execution''. An \textit{inverse interpreter}
thus receives a program and some output and calculates the set of
possible inputs that could give rise to such output. As an example, a
program \texttt{substring} is a function that determines whether its
first argument is a sublist of its second argument. When doing normal
forward computation we will always return a single boolean result, as
in these examples:
\begin{align*}
& \texttt{sublist ['o, ['o, 'nil]] ['f, ['o, ['o, 'nil]]]} \\
& \quad => \texttt{'true} \\
& \texttt{sublist ['b, ['a, 'nil]] ['f, ['o, ['o, 'nil]]]} \\
& \quad => \texttt{'false}
\end{align*}
When we want to use URA to do inverse computation on this function, we
hand it the output together with a specification of the structural
form of the input.
\begin{align*}
  &\texttt{ura sublist ($X_1$, ['f, ['o, ['o, 'nil]]]) 'true} \\
  & => \textit{all sublists of ``foo''}
\end{align*}
In this case \texttt{($X_1$, ['f, ['o, ['o, 'nil]]])} serve as a
specification of the possible input arguments and \texttt{'true}
specifies the output. Here the second argument is fixed to the list
representing ``foo'', but we only specify some metavariable as the
input for the first argument. A solution from URA will compute all
possible substitutions of such metavariables that will give rise to
the output \texttt{'true}. It is in this sense that the algorithm is
universal. An existential algorithm would just find a single input
value.

The universal algorithm is made for inverse interpretation, but it can
also be used for the problem of \textit{program inversion}. Using a
self-interpreter and the Futamura-projections, a \textit{program
  inverter} can be obtained from the program interpreter. This is much
related to how a compiler can be obtained from an interpreter through
the use of a partial evaluator. The exact way this is done, is shown
in the paper ``The Principles of the Universal Resolving Algorithm''
\cite{abramov2000universal}.

\section{Subject Language}
In this paper we will study a small syntactically typed functional
language, that draws inspiration from both the language studied in
\cite{sorensen1998introduction} and the S-Graph language as defined in
the papers on the Universal Resolving Algorithm
\cite{abramov2000universal, abramov2002universal,
  abramov2002principles}.

\subsection{Syntax}
The syntax of our language is defined in Figure \ref{fig:bnf}. A
program, $p \in \mathcal{P}$, is a sequence of function definitions. A
function definition, $d \in \mathcal{D}$, can have two forms, either
they are pattern matching and are called \textit{G-functions} or they
are not and then called \textit{F-functions}. To distinguish, we use
the convention of naming all \textit{G-functions} with an initial
capital letter, and \textit{F-functions} with a lower case
letter. Functions can take any number of arguments and for
\textit{G-functions}, the first argument (and only that) must always
be a pattern-match.

Terms $t \in \mathcal{T}$ are either function calls (of the two
types), a conditional or an expression. We have two categories of
expressions. Atomic expressions, $ea \in \mathcal{A}$, can range over
only \textit{atoms} (which are prefixed with an apostrophe, such as
the symbol \texttt{'coffee}) and atomic variables $\texttt{.}x \in
\mathcal{A}$. This distinction between atomic variables
($\texttt{.}x$ and expressions variables $x$ serves as a simply type
system. A conditional can only compare atomic variables and the only
comparison allowed is equality testing.

Ordinary expressions, can in addition to being atomic expressions, use
a \textit{cons}-operation to form pairs of values. These can be used
to construct lists, trees or other data-structures, as well as be used
for number-representation (Peano-numbers).


\begin{figure}\centering
  \begin{align*}
    \mathcal{P} \ni p ::= & d^{+}\tag{Program}\\
    \mathcal{D} \ni d ::= &\texttt{fun \textit{\rmfamily fname} $x^{*}$ = $t$}  \tag{Definition} \\
    | \quad &\texttt{fun \textit{\rmfamily gname} [$x_1$, $x_2$] $x^{*}$ = $t_1$} \\
    & \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{.7cm} $x^{*}$ = $t_2$}\\
    \mathcal{T} \ni t ::= & \texttt{\textit{\rmfamily fname} $x^{*}$}  \tag{Term}\\
    | \quad & \texttt{\textit{\rmfamily gname} $x^{*}$} \\
    | \quad & \texttt{if $ea_1 = ea_2$ then $t_1$ else $t_2$} \\
    | \quad & e \\
    \mathcal{E} \ni e ::= & \texttt{[$e_1$, $e_2$]} \tag{Expression}\\
    | \quad & x \\
    | \quad & ea \\
    \mathcal{A} \ni ea ::= & \texttt{'}s \tag{Atomic expression}\\
    | \quad & \texttt{.}x
  \end{align*}
  \caption{Syntax of TRFL.}
\label{fig:bnf}
\end{figure}

\subsection{Value-classes}
Values in our language can either be \textit{atoms} or pairs of
values. Pairs are constructed using the \textit{cons}-operation as
described above. A value is \textit{ground} if it does not contain any
variables. We denote ground values as by $va \in AVal$ and $v \in Val$
depending on whether they only contain atoms.

\begin{figure}\centering
  \begin{align*}
    Val \ni v ::= & \texttt{[$v_1$, $v_2$]}\ |\ va\\
    AVal \ni va ::= & \texttt{'}s
  \end{align*}
  \caption{Values in TRFL.}
\label{fig:bnf}
\end{figure}

As explained, the result of inverse-computation on non-injective
functions might result in several input values for one input. The set
of inputs might even be infinite. We represent these classes of
inputs, by placing meta-variables in the places where they vary, and
registering constraints that should be obeyed by these variables.  We
call such generalized values for \textit{C-expressions}, and we use
the word \textit{contractions} to denote the constraints on
meta-variables occurring in C-expressions. The domain of
C-expressions is shown in Figure \ref{fig:cbnf} as
$\mathcal{\widehat{A}}$ and $\mathcal{\widehat{E}}$. In addition we
define terms containing such meta variables, these are denoted
$\widehat{t} \in \widehat{\mathcal{T}}$.

A good analogy for these input-classes is the ZF-notation for
describing mathematical sets, where we represent the left-hand side by
\textit{C-expressions} and the right-hand side is used to specify the
constraints on the meta-variables occurring in the
\textit{C-expression}. 

\begin{figure}\centering
  \begin{align*}
    \widehat{\mathcal{T}} \ni \widehat{t}
      ::=& \texttt{\textit{\rmfamily fname} $x^{*}$} \tag{C-Term} \\
    | \quad & \texttt{\textit{\rmfamily gname} $x^{*}$} \\
    | \quad & \texttt{if $\widehat{ea_1} = \widehat{ea_2}$ then $\widehat{t_1}$ else $\widehat{t_2}$} \\
    | \quad & \widehat{e} \\
    \widehat{\mathcal{E}} \ni \widehat{e} ::=& \texttt{[$\widehat{e_1}$, $\widehat{e_2}$]} \tag{C-Expression} \\
    | \quad & \widehat{Xe} \\
    | \quad & \widehat{ea} \\
    \widehat{\mathcal{A}} \ni \widehat{ea} ::= & \texttt{'}s \tag{Atomic C-expression} \\
    | \quad & \widehat{Xa}
  \end{align*}

\caption{Syntax of terms and expressions with meta variables}
\label{fig:cbnf}
\end{figure}

\subsection{Semantics}
Terms in TRFL are parameterized over an environment $\sigma$ and
the set of function definitions $\Gamma$. The operational semantics is
shown in Figure \ref{fig:semantics} using judgement form: $\sigma
|-_\Gamma t => v$. A judgement of this form should be interpreted as:
\textit{given environment $\sigma$ and function definitions $\Gamma$,
  the term $t$ evaluates to the value $v$.}

\section{Universal resolving algorithm}
The Universal Resolving Algorithm is partitioned into three separate
steps. This section serves as a short introduction to the universal
resolving algorithm as explained in \cite{abramov2000universal,
  abramov2002universal, abramov2002principles}. We will not go into
specific details, as these can be found in the referenced papers.

% To explain the individual steps we will perform inverse computation of
% a simple addition example program.
% \begin{verbatim}
% fun Add [s, ss] y = Add ss ['S, y]
%   | Add .z y = if .z == 'Z
%                then y
%                else 'error-unknown-symbol
% \end{verbatim}

\subsection{Tracing: Obtaining a Perfect Process Tree}
The first step of the universal resolving algorithm, is to trace all
possible execution paths of the program, to obtain a \textit{process
  tree} of such traces. Tracing a program to obtain a perfect process
tree is done on the basis of some input class. In the most general
case, this input-class can be specified as all possible values (a
single meta-variable for each argument), but it can often be desirable
to restrict the set of possible inputs to a certain form, such as ``a
three element list of values''. This can be used to make the answer
returned by URA finite.

Tracing is conducted by stepping through the semantics of the
language, creating a new node for each step. Because we have an
input-class rather than a concrete input value, certain conditionals
in the program might not be decidable, we thus create branches for
each possibility. When the tree branches, certain circumstances
regarding the input must hold to follow each of the two edges. The
\textit{contractions} on the input class, that must hold to follow a
specific edge together with the edge.

To summarize, a node in a process tree represents a point of
evaluation of the program. The contractions found on the path from the
root down to a node, represents the conditions on the input that must
hold for this path to be followed. The terminal nodes (leafs) in the
process tree represents the output returned by following the path from
root to leaf.

% example ?

\subsection{Tabulation}
On the basis of the process tree, the relationships between inputs and
outputs can be obtained by following all paths in the tree, from the
root to each leaf. The contractions found on the path down to this
leaf, are conditions on the input, that should hold before the output
stored in the node is returned.

Tabulation is the process of walking the tree and for each output
(represented by a leaf) write down the associated conditions that
should be obeyed by the input.

\subsection{Inversion}
The final step of URA is to extract the answers for a given output
from the table of input/output pairs, to obtain the set of
corresponding input values. The desired output given as argument to
URA is unified with each output class in the table, the resulting
replacement is then applied to relevant input-specification and the
set of contractions is checked for contradictions.

\begin{figure*}
  \begin{align}
    \nfrac{
      \widehat{ea_1} = \widehat{ea_2}
    }{
      |-_\Gamma \texttt{if $\widehat{ea_1}$ = $\widehat{ea_2}$ then $\widehat{t_1}$ else $\widehat{t_2}$} => <<\widehat{t_1}, \kappa_{id}>>
    } \tagsc{If-Eq}
\\\nonumber\\
    \nfrac{
      \widehat{ea_1} \neq \widehat{ea_2} \quad \kappa = (\widehat{ea_1}\ \#\ \widehat{ea_2})
    }{
      |-_\Gamma \texttt{if $\widehat{ea_1}$ = $\widehat{ea_2}$ then $\widehat{t_1}$ else $\widehat{t_2}$} => <<\widehat{t_2}, \kappa>>
    } \tagsc{If-Neq-False}
\\\nonumber\\
    \nfrac{
      \widehat{ea_1} \neq \widehat{ea_2} \quad (\widehat{ea_1}\ \#\ \widehat{ea_2}) \not \in \textrm{Tauto} \quad \kappa = [\textrm{mkBind}(\widehat{ea_1}, \widehat{ea_2})]
    }{
      |-_\Gamma \texttt{if $\widehat{ea_1}$ = $\widehat{ea_2}$ then $\widehat{t_1}$ else $\widehat{t_2}$} => <<\widehat{t_1}, \kappa>>
    } \tagsc{If-Neq-True}
  \end{align}

  ~\newline

  \begin{align}
    \nfrac{
      \begin{array}{c}
        \widehat{e_0} = [\widehat{e_\alpha}, \widehat{e_\beta}] \quad \theta = \{ x_\alpha := \widehat{e_\alpha}, x_\beta := \widehat{e_\beta}, x_1 := \widehat{e_1}, ..., x_n := \widehat{e_n} \} \\
        \Gamma(\textit{gname}) =
        \begin{array}{l}
          \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
          \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{0.95cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
        \end{array}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily gname} $\widehat{e_0}$ ... $\widehat{e_n}$} => <<t_1 / \theta, \kappa_{id} >>
    } \tagsc{Case-Cons}
\\\nonumber\\
    \nfrac{
      \begin{array}{c}
        \widehat{e_0} = \widehat{ea} \quad \theta = \{ .x := \widehat{ea}, x_1' := \widehat{e_1}, ..., x_n' := \widehat{e_n} \} \\
        \Gamma(\textit{gname}) =
        \begin{array}{l}
          \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
          \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{0.95cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
        \end{array}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily gname} $\widehat{e_0}$ ... $\widehat{e_n}$} => << t_2 / \theta, \kappa_{id}>>
    } \tagsc{Case-Atom}
\\\nonumber\\
    \nfrac{
      \begin{array}{c}
        \widehat{e_0} = \widehat{Xe} \quad \theta = \{ x_\alpha := \widehat{X_{e_1}^\diamond}, x_\beta := \widehat{X_{e_2}^\diamond}, x_1 := \widehat{e_1}, ..., x_n := \widehat{e_n} \} \\
        \kappa = [\widehat{Xe} \mapsto [\widehat{X_{e_1}^\diamond}, \widehat{X_{e_2}^\diamond}]] \\
        \Gamma(\textit{gname}) =
        \begin{array}{l}
          \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
          \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{0.95cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
        \end{array}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily gname} $\widehat{e_0}$ ... $\widehat{e_n}$} => <<t_1 / \theta, \kappa>>
    } \tagsc{Case-Var-Cons}
\\\nonumber\\
    \nfrac{
      \begin{array}{c}
        \widehat{e_0} = \widehat{Xe} \quad \theta = \{ .x := \widehat{X_{a}^\diamond}, x_1' := \widehat{e_1'}, ..., x_n' := \widehat{e_n'} \} \\
        \kappa = [\widehat{Xe} \mapsto \widehat{Xa^\diamond}] \\
        \Gamma(\textit{gname}) =
        \begin{array}{l}
          \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
          \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{0.95cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
        \end{array}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily gname} $\widehat{e_0}$ ... $\widehat{e_n}$} => <<t_2 / \theta, \kappa>>
    } \tagsc{Case-Var-Atom}
  \end{align}

  ~\newline

  \begin{equation}
    \nfrac{
      \begin{array}{c}
        \Gamma(\textit{fname}) =
          \texttt{fun \textit{\rmfamily fname} $x_1$ $\ldots$ $x_n$ = $t$} \\
        \theta = \{ x_1 := \widehat{e_1}, ..., x_n := \widehat{e_n} \}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily fname} $\widehat{e_1}$ ... $\widehat{e_n}$} => <<t / \theta, \kappa_{id}>>
    } \tagsc{Call}
  \end{equation}

  \caption{Trace semantics}
  \label{fig:tracing}
\end{figure*}

\section{Supercompilation}
In supercompilation, one wishes to obtain more efficient forms of a
program by observing their execution and generating a new program with
similar functionality. For instance two functions that operate
independently, might be more efficiently described by composing them
into one program (program composition). Another example is program
specialization, where parts of the input is known is advance, and
supercompilation can be a way of obtaining a more efficient version of
the program when this information is taken into account.

Supercompilation, like the universal resolving algorithm, follows the
execution of a program with variable as input. The universal resolving
algorithm has been inspired by these techniques from
supercompilation. In supercompilation, the term \textit{driving} is
used to describe the act of finding a process tree.

\subsection{Generalization}
A process tree found in super compilation should be finite, as we want
to output a finite output in the end.

\section{Generalization in the PPT}
Here we will show how to create the perfect process tree in a way such
that we obtain a finite representation. This is done using techniques
from \textit{positive supercompilation} by defining a homeomorphic
embedding of terms. The embedding is shown on Figure
\ref{fig:embedding}.

\section{Closed URA}
% This section will replace parts of the previous section
Given a TRFL program and a partially specified input, the \emph{Closed
  URA} (CURA) algorithm creates a process tree representing the
possible state transitions of the program. Like URA, CURA
non-deterministically branches when it cannot decide the flow of
control resulting from the partially specified input, applying
\emph{perfect splits} to split the set of possible inputs into
disjoint sets, one for each branch.

As described earlier, URA is based on walking an often infinite
process tree, creating a table of pairs of output and input sets. CURA
is an off-line algorithm that outputs a closed representation of the
process tree. The closed process tree is not a solution to the
inversion problem in itself, but may serve as a useful representation
for creating specialized search programs.

\subsection{Preliminaries}
We use the same definition of trees as in
\cite{sorensen1998introduction}. That is, a tree over a set $E$ is a
partial function $t : \mathbb{N}_1^\star \rightarrow E$, with the
usual restrictions required for representing finitely branching trees
(see \cite{sorensen1998introduction}\cite{courcelle1983fundamental}
for details).

By $\dom(t)$ we denote the set of nodes in tree $t$, and by
$t(\alpha)$ we denote the label at node $\alpha$. ${\rm anc}(t,
\alpha)$ denotes the set of ancestors for node $\alpha$ in tree $t$,
and for some $\alpha \in \dom(t)$, $t\{\alpha := t'\}$ denotes the
tree obtained from $t$ by replacing the subtree rooted at node
$\alpha$ with $t'$.

The tree $e \rightarrow e_1, ..., e_n$ is the tree with root labeled
$e$ and children labeled $e_1, ..., e_n$.

\subsection{Trace semantics}
The trace semantics for TRFL can be seen in Figure
\ref{fig:tracing}. The semantics are non-deterministic when a branch
cannot be decided, and therefore describes an infinite process tree.

A C-term $\widehat{t}$ in our language fully describes a given set of
program states, and the semantics therefore describes transitions
between C-terms. Each transition is associated with a
\emph{contraction} $\kappa$, which reflects the constraint that must
be true to reach the destination state.

\subsection{Closed trees}
In order to ensure that the resulting process tree is finite, we have

\begin{figure*}\centering
  \begin{align*}
    \widehat{\mathcal{L}} \ni \widehat{l} ::= & \texttt{let $\widehat{X_1} = \widehat{e_1} ... \widehat{X_n} = \widehat{e_n}$ in $\widehat{t}$}
  \end{align*}
  \caption{Syntax of let-generalized C-terms}
\end{figure*}

\section{Size-change termination analysis}

\begin{figure*}\centering
  \begin{equation}
    \nfrac{
    }{
      \texttt{'}s_1 <| \texttt{'}s_2
    } (s_1 = s_2) \tagsc{Atoms}
  \end{equation}

  \begin{equation}
    \nfrac{
    }{
      \texttt{.}x_1 <| \texttt{.}x_2
    }
    \qquad
    \nfrac{
    }{
      x_1 <| x_2
    }
    \qquad
    \nfrac{
    }{
      \texttt{.}x_1 <| x_2
    } \tagsc{Variables}
  \end{equation}

  \begin{equation}
    \nfrac{
      e_1 <| e_1'\quad e_2 <| e_2'
    }{
      \texttt{[$e_1$, $e_2$]} <| \texttt{[$e_1'$, $e_2'$]}
    }
    \qquad
    \nfrac{
      e <| e_1
    }{
      e <| \texttt{[$e_1$, $e_2$]}
    }
    \qquad
    \nfrac{
      e <| e_2
    }{
      e <| \texttt{[$e_1$, $e_2$]}
    }
    \tagsc{Cons}
  \end{equation}

  \begin{equation}
    \nfrac{
      ea_1 <| ea_1' \quad ea_2 <| ea_2' \quad t_1 <| t_1' \quad t_2 <| t_2'
    }{
      \texttt{if $ea_1$ = $ea_2$ then $t_1$ else $t_2$} <| \texttt{if $ea_1'$ = $ea_2'$ then $t_1'$ else $t_2'$}
    } \tagsc{If-A}
  \end{equation}

  \begin{equation}
    \nfrac{
      \exists t' \in \{ea_1, ea_2, t_1, t_2\}. t <| t'
    }{
      t <| \texttt{if $ea_1$ = $ea_2$ then $t_1$ else $t_2$}
    } \tagsc{If-B}
  \end{equation}

\begin{equation}
  \nfrac{
    \forall i \in \{0, \ldots, n\}. e_i <| e_i'
  }{
    h(e_0, \ldots, e_n) <| h(e_0', \ldots, e_n')
  } (h \in G \cup F)
  \qquad
  \nfrac{
    \exists i \in \{0, \ldots, n\}. e <| e_i'
  }{
    e <| h(e_0', \ldots, e_n')
  }
 \tagsc{Call}
\end{equation}

\caption{Homeomorphic embedding relation}
\label{fig:embedding}
\end{figure*}


\section{Future Work}
\subsection{Size-change termination analysis}
  The Size-Change Termination Analysis (SCTA)\cite{lee2001size} can be
  used to identify programs that terminate for all inputs, and
  size-change graphs resulting from this approach may be used to cut
  branches in a process tree, minimizing its size. We are not aware of
  any uses of SCTA in the field of inverse interpretation, but in this
  report we will investigate whether this approach is feasible.



\bibliographystyle{abbrvnat}
\bibliography{../bibliography}

\appendix
\section{TRFL Semantics}
\begin{figure*}\centering
  \begin{equation}
    \nfrac{
      ea_1/ \sigma = ea_2/\sigma \quad
      \sigma |-_\Gamma t_1 => v_1
    }{
      \sigma |-_\Gamma \texttt{if $ea_1$ = $ea_2$ then $t_1$ else $t_2$} => v_1
    }
    \qquad
    \nfrac{
      ea_1/ \sigma \neq ea_2/\sigma \quad
      \sigma |-_\Gamma t_2 => v_2
    }{
      \sigma |-_\Gamma \texttt{if $ea_1$ = $ea_2$ then $t_1$ else $t_2$} => v_2
    } \tagsc{If}
\end{equation}

\begin{equation}
\hspace{-0.7cm}
  \nfrac{
    \begin{array}{c}
      \Gamma(\textit{gname}) =
      \begin{array}{l}
        \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
        \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{1.1cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
      \end{array} \\
      e_0/\sigma = \texttt{[$v_1$, $v_2$]} \\
      \sigma\{x_\alpha |-> v_1, x_\beta |-> v_2, x_1 |-> e_1/\sigma, \ldots, x_n |-> e_n/\sigma\} |-_\Gamma t_1 => v_1
    \end{array}
  }{
    \sigma |-_\Gamma \texttt{\textit{\rmfamily gname} $e_0$ $e_1$ $\ldots$ $e_n$} => v_1
  }
\qquad
  \nfrac{
    \begin{array}{c}
      \Gamma(\textit{gname}) =
      \begin{array}{l}
        \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
        \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{1.1cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
      \end{array} \\
      e_0/\sigma = \texttt{'}s \\
      \sigma\{\texttt{.}x |-> \texttt{'}s, x_1' |-> e_1/\sigma, \ldots, x_n' |-> e_n/\sigma\} |-_\Gamma t_1 => v_1
    \end{array}
  }{
    \sigma |-_\Gamma \texttt{\textit{\rmfamily gname} $e_0$ $e_1$ $\ldots$ $e_n$} => v_1
  }
  % \nfrac{
  %   \begin{array}{c}
  %     \Gamma(\textit{gname}) =
  %     \begin{array}{l}
  %       \texttt{fun \textit{\rmfamily gname} [$x_1$, $x_2$] $x_3$ $\ldots$ $x_n$ = $t_1$} \\
  %       \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{.7cm} $x_3'$ $\ldots$ $x_n'$ = $t_2$} \\
  %     \end{array} \\
  %     e_1/\sigma = \texttt{'$s$} \\
  %     \sigma\{\texttt{.}x |-> \texttt{'}s, x_3' |-> e_2/\sigma, \ldots, x_n' |-> e_n/\sigma\} |-_\Gamma t_2 => v_2
  %   \end{array}
  % }{
  %   \sigma |-_\Gamma \texttt{\textit{\rmfamily gname} $e_1$ $e_2$ $\ldots$ $e_n$} => v_2
  % }
  \tagsc{Call-G}
\end{equation}

\begin{equation}
  \nfrac{
    \begin{array}{c}
      \Gamma(\textit{fname}) =
        \texttt{fun \textit{\rmfamily fname} $x_1$ $x_2$ $\ldots$ $x_n$ = $t$}
        \\
      \sigma\{x_1 |-> e_1/\sigma, x_2 |-> e_2/\sigma, \ldots, x_n |-> e_n/\sigma\} |-_\Gamma t => v
    \end{array}
  }{
    \sigma |-_\Gamma \texttt{\textit{\rmfamily fname} $e_1$ $e_2$ $\ldots$ $e_n$} => v
  } \tagsc{Call-F}
\end{equation}


\caption{Operational Semantics for TSG'}
\label{fig:semantics}
\end{figure*}





\end{document}
