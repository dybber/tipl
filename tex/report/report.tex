\documentclass[10pt]{../sigplanconf}

\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{semantic}
\usepackage{amsthm}

\conferenceinfo{DIKU workshop on Topics in Programming Languages,}{June 2011.}
\title{To Trim a Perfect Process Tree}
%\subtitle{Subtitle Text, if any}
\authorinfo{Martin Dybdal}
           {dybber@dybber.dk}
           {DIKU, Department of Computer Science, University of Copenhagen}
\authorinfo{Ulrik Rasmussen}
           {dolle@diku.dk}
           {DIKU, Department of Computer Science, University of Copenhagen}
\authorpermission
\copyrightdata{draft}

\mathlig{::=}{\quad ::=\quad}
\mathlig{|->}{\mapsto}
\mathlig{<|}{\trianglelefteq}
\mathlig{<<}{\langle}
\mathlig{>>}{\rangle}
\newcommand{\dom}{\ensuremath{{\rm dom}}}
\newcommand{\anc}{\ensuremath{{\rm anc}}}

% For proofs, As frac but does not change the font size
\newcommand{\nfrac}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}
% Small-caps tags
\newcommand{\tagsc}[1]{\tag{\scshape #1}}
\newtheorem{definition}{Definition}

\begin{document}
\maketitle

\begin{abstract}
  The \textit{Universal Resolving
    Algorithm}\cite{abramov2000universal} is an algorithm for inverse
  interpretation, based on the notion of a \textit{perfect process
    tree} \cite{gluck1993occam} for representing the possible traces
  of a program. Such process trees can possibly have an infinite
  representation, and thus the universal resolving algorithm is not
  guaranteed to terminate.

  In this paper we investigate how to obtain a finite, closed
  representation of process trees useful in the universal resolving
  algorithm.

  Generation of process trees by driving is a technique that
  originates from the field of
  supercompilation\cite{sorensen1998introduction}. A positive
  supercompiler uses a technique called \emph{generalization} to
  ensure that it will eventually arrive at a process tree with a
  finite representation, which still represents all possible
  configurations of the program. To our knowledge, the same technique
  has not been applied to the field of inverse interpretation.
\end{abstract}

\keywords Inverse Interpretation, Generalization, Universal Resolving
Algorithm.
\begin{center}
  \vspace{0.5cm}
  \includegraphics[width=0.6\columnwidth]{../figures/pruning.pdf}
  \vspace{0.5cm}
\end{center}

\newpage
\section{Introduction}
Conventionally, when we execute a program, we hand it some an input
value and after some time it returns with an output. In the field of
\textit{inverse interpretation}, we seek to reverse this process, by
handing the same program its output and then finding the possible
inputs by ``backwards execution''. An \textit{inverse interpreter}
thus receives a program and some output and calculates the set of
possible inputs that could give rise to such output. As an example, a
program \texttt{substring} is a function that determines whether its
first argument is a sublist of its second argument. When doing normal
forward computation we will always return a single boolean result, as
in these examples:
\begin{align*}
& \texttt{sublist ['o, ['o, 'nil]] ['f, ['o, ['o, 'nil]]]} \\
& \quad => \texttt{'true} \\
& \texttt{sublist ['b, ['a, 'nil]] ['f, ['o, ['o, 'nil]]]} \\
& \quad => \texttt{'false}
\end{align*}
When we want to use URA to do inverse computation on this function, we
hand it the output together with a specification of the structural
form of the input.
\begin{align*}
  &\texttt{ura sublist ($X_1$, ['f, ['o, ['o, 'nil]]]) 'true} \\
  & => \textit{all sublists of ``foo''}
\end{align*}
In this case \texttt{($X_1$, ['f, ['o, ['o, 'nil]]])} serve as a
specification of the possible input arguments and \texttt{'true}
specifies the output. Here the second argument is fixed to the list
representing ``foo'', but we only specify some metavariable as the
input for the first argument. A solution from URA will compute all
possible substitutions of such metavariables that will give rise to
the output \texttt{'true}. It is in this sense that the algorithm is
universal. An existential algorithm would just find a single input
value.

The universal algorithm is made for inverse interpretation, but it can
also be used for the problem of \textit{program inversion}. Using a
self-interpreter and the Futamura-projections, a \textit{program
  inverter} can be obtained from the program interpreter. This is much
related to how a compiler can be obtained from an interpreter through
the use of a partial evaluator. The exact way this is done, is shown
in the paper ``The Principles of the Universal Resolving Algorithm''
\cite{abramov2000universal}.


\section{Universal resolving algorithm}
This section serves as a short, informal introduction to the Universal
Resolving Algorithm as explained in \cite{abramov2000universal,
  abramov2002universal, abramov2002principles}. We will not go into
specific details, as these can be found in the referenced
papers. Examples of the individual steps can be found in
\cite{abramov2000universal}.

\subsection{Tracing: Obtaining a Perfect Process Tree}
The first step of the universal resolving algorithm, is to trace all
possible execution paths of the program, to obtain a \textit{process
  tree} of such traces. Tracing is done on the basis of some
specification of the shape of input values. Such a specification is
called an \textit{input class}. In the most general case, this
input-class can be specified as all possible values. This done by
specifying a single meta-variable for each argument, with out any
further restrictions. It can often be desirable to restrict the set of
possible inputs to a certain form, such as ``a three element list of
values''. This can be done by specifying that the input is such a
list, with a new meta-variables at each position in the list. Such
restrictions can be useful to force a finite answer from URA. 

Tracing is conducted by stepping through the semantics of the
language, creating a new node for each step. Because we have an
input-class rather than a concrete input value, certain conditionals
in the program might not be decidable. We thus create branches for
each possibility and tag each of the edges with the conditions on the
input that should hold to follow them. These conditions are named
\textit{contractions} on the input class.

To summarize, a node in a process tree represents a point of
evaluation of the program. The contractions found on the path from the
root down to a node, represents the conditions on the input that must
hold for this path to be followed. The terminal nodes (leafs) in the
process tree represents the output returned by following the path from
root to leaf.

% example ?

\subsection{Tabulation}
On the basis of the process tree, the relationships between inputs and
outputs can be obtained by following all paths in the tree, from the
root to each leaf. The contractions found on the path down to this
leaf, are conditions on the input, that should hold for program to
return the output stored in the node.

Tabulation is the process of walking the tree and for each output
(represented by a leaf) write down the associated conditions that
should be obeyed by the input.

\subsection{Inversion}
The final step of URA is to extract the answers for a given output
from the table of input/output pairs, to obtain the set of
corresponding input values. The desired output given as argument to
URA is unified with each output class in the table, the resulting
replacement is then applied to relevant input-specification and the
set of contractions is checked for contradictions.

\subsection{Perfect Process Trees}
A \textit{perfect} process tree \cite{gluck1993occam}, is a process
tree without any infeasible paths. A path is infeasible if there is no
input such that the path is taken. The universal solving algorithm
always constructs perfect process trees, as branches are only created
in the tree if no contradictions between contractions occur along the
path from the root and splits in the tree are perfect, in the sense
that an input value only gives rise to a single path through the
tree. We will show how to obtain a finite representation of a process
tree, but in doing so, we will discard perfectness. In general, if a
process tree is perfect, it can not be finite. This will be detailed
in following sections.

\section{Supercompilation}
In supercompilation, one wishes to obtain more efficient programs by
observing their execution and generating new programs with equivalent
functionality. For instance two functions that operate independently,
might be more efficiently described by composing them into one program
(program composition). Another example is program specialization,
where parts of the input is known in advance, and supercompilation can
be a way of obtaining a more efficient version of the program when
this information is taken into account.

Supercompilation, like the universal resolving algorithm, makes a
controlled execution of the program, constructing a process tree of
the possible edges. In supercompilation, this technique of observing
the execution of a program is called \textit{driving}. The universal
resolving algorithm has been inspired by the techniques from
supercompilation \cite{abramov2002principles}.

\subsection{Generalization}
As the output of supercompilation is a new program, the process trees
generated must be kept finite to guarantee termination. Alternatively,
the generated program would also be infinite. The process tree is made
finite by interleaving normal driving steps that generates the tree,
with steps that decides whether a back edge can be made to a previous
equivalent expression in an ancestor node. This is still not enough to
guarantee termination, as there are examples where the program
iterates for ever, but continues to build up larger and larger
expressions, thus never finding a place to add a back edge.

This problem is solved by adding generalizing steps. Instead of
checking that a \textit{renaming} of the expression occurs as an
ancestor, the ancestors are checked for another kind of ``similarity''
(we will detail this later) and if a similar ancestor is found, a
generalised expression of the node and the ancestor is made, such they
both are instances of the new general node.

\section{Subject Language}
In this paper we will study a small syntactically typed functional
language, that draws inspiration from both the language studied in
\cite{sorensen1998introduction} and the S-Graph language as defined in
the papers on the Universal Resolving Algorithm
\cite{abramov2000universal, abramov2002universal,
  abramov2002principles}.

\subsection{Syntax}
The syntax of our language is defined in Figure \ref{fig:bnf}. A
program, $p \in \mathcal{P}$, is a sequence of function definitions. A
function definition, $d \in \mathcal{D}$, can have two forms, either
they are pattern matching and are called \textit{G-functions} or they
are not and then called \textit{F-functions}. To distinguish, we use
the convention of naming all \textit{G-functions} with an initial
capital letter, and \textit{F-functions} with a lower case
letter. Functions can take any number of arguments and for
\textit{G-functions}, the first argument (and only that) must always
be a pattern-match.

Terms $t \in \mathcal{T}$ are either function calls (of the two
types), a conditional or an expression. We have two categories of
expressions. Atomic expressions, $ea \in \mathcal{A}$, can range over
only \textit{atoms} (which are prefixed with an apostrophe, such as
the symbol \texttt{'coffee}) and atomic variables $\texttt{.}x \in
\mathcal{A}$. This distinction between atomic variables
($\texttt{.}x$ and expressions variables $x$ serves as a simply type
system. A conditional can only compare atomic variables and the only
comparison allowed is equality testing.

Ordinary expressions, can in addition to being atomic expressions, use
a \textit{cons}-operation to form pairs of values. These can be used
to construct lists, trees or other data-structures, as well as be used
for number-representation (Peano-numbers).


\begin{figure}\centering
  \begin{align*}
    \mathcal{P} \ni p ::= & d^{+}\tag{Program}\\
    \mathcal{D} \ni d ::= &\texttt{fun \textit{\rmfamily fname} $x^{*}$ = $t$}  \tag{Definition} \\
    | \quad &\texttt{fun \textit{\rmfamily gname} [$x_1$, $x_2$] $x^{*}$ = $t_1$} \\
    & \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{.7cm} $x^{*}$ = $t_2$}\\
    \mathcal{T} \ni t ::= & \texttt{\textit{\rmfamily fname} $x^{*}$}  \tag{Term}\\
    | \quad & \texttt{\textit{\rmfamily gname} $x^{*}$} \\
    | \quad & \texttt{if $ea_1 = ea_2$ then $t_1$ else $t_2$} \\
    | \quad & e \\
    \mathcal{E} \ni e ::= & \texttt{[$e_1$, $e_2$]} \tag{Expression}\\
    | \quad & x \\
    | \quad & ea \\
    \mathcal{A} \ni ea ::= & \texttt{'}s \tag{Atomic expression}\\
    | \quad & \texttt{.}x
  \end{align*}
  \caption{Syntax of TRFL.}
\label{fig:bnf}
\end{figure}

\subsection{Value-classes}
Values in our language can either be \textit{atoms} or pairs of
values. Pairs are constructed using the \textit{cons}-operation as
described above. A value is \textit{ground} if it does not contain any
variables. We denote ground values as by $va \in AVal$ and $v \in Val$
depending on whether they only contain atoms.

\begin{figure}\centering
  \begin{align*}
    Val \ni v ::= & \texttt{[$v_1$, $v_2$]}\ |\ va\\
    AVal \ni va ::= & \texttt{'}s
  \end{align*}
  \caption{Values in TRFL.}
\label{fig:bnf}
\end{figure}

As explained, the result of inverse-computation on non-injective
functions might result in several input values for one input. The set
of inputs might even be infinite. We represent these classes of
inputs, by placing meta-variables in the places where they vary, and
registering constraints that should be obeyed by these variables.  We
call such generalized values for \textit{C-expressions}, and we use
the word \textit{contractions} to denote the constraints on
meta-variables occurring in C-expressions. The domain of
C-expressions is shown in Figure \ref{fig:cbnf} as
$\mathcal{\widehat{A}}$ and $\mathcal{\widehat{E}}$. In addition we
define terms containing such meta variables, these are denoted
$\widehat{t} \in \widehat{\mathcal{T}}$.

A good analogy for these input-classes is the ZF-notation for
describing mathematical sets, where we represent the left-hand side by
\textit{C-expressions} and the right-hand side is used to specify the
constraints on the meta-variables occurring in the
\textit{C-expression}. 

\begin{figure}\centering
  \begin{align*}
    \widehat{\mathcal{T}} \ni \widehat{t}
      ::=& \texttt{\textit{\rmfamily fname} $x^{*}$} \tag{C-Term} \\
    | \quad & \texttt{\textit{\rmfamily gname} $x^{*}$} \\
    | \quad & \texttt{if $\widehat{ea_1} = \widehat{ea_2}$ then $\widehat{t_1}$ else $\widehat{t_2}$} \\
    | \quad & \widehat{e} \\
    \widehat{\mathcal{E}} \ni \widehat{e} ::=& \texttt{[$\widehat{e_1}$, $\widehat{e_2}$]} \tag{C-Expression} \\
    | \quad & \widehat{Xe} \\
    | \quad & \widehat{ea} \\
    \widehat{\mathcal{A}} \ni \widehat{ea} ::= & \texttt{'}s \tag{Atomic C-expression} \\
    | \quad & \widehat{Xa} \\
    \tag{Generalized C-term} \\
    \widehat{\mathcal{L}} \ni \widehat{l} ::= & \texttt{let $\widehat{X_1} = \widehat{e_1} ... \widehat{X_n} = \widehat{e_n}$ in $\widehat{t}$}
  \end{align*}

\caption{Syntax of terms and expressions with meta variables}
\label{fig:cbnf}
\end{figure}

\subsection{Semantics}
Terms in TRFL are parameterized over an environment $\sigma$ and
the set of function definitions $\Gamma$. The operational semantics is
shown in Figure \ref{fig:semantics} using judgement form: $\sigma
|-_\Gamma t => v$. A judgement of this form should be interpreted as:
\textit{given environment $\sigma$ and function definitions $\Gamma$,
  the term $t$ evaluates to the value $v$.}

\section{Generalization in the PPT}
Here we will show how to create the perfect process tree in a way such
that we obtain a finite representation. This is done using techniques
from \textit{positive supercompilation} by defining a homeomorphic
embedding of terms. The embedding is shown on Figure
\ref{fig:embedding}.

\section{Closed URA}
% This section will replace parts of the previous section
Given a TRFL program and a partially specified input, the \emph{Closed
  URA} (CURA) algorithm creates a process tree representing the
possible state transitions of the program. Like URA, CURA
non-deterministically branches when it cannot decide the flow of
control resulting from the partially specified input, applying
\emph{perfect splits} to split the set of possible inputs into
disjoint sets, one for each branch.

As described earlier, URA is based on walking an often infinite
process tree, creating a table of pairs of output and input sets. CURA
is an off-line algorithm that outputs a closed representation of the
process tree. The closed process tree is not a solution to the
inversion problem in itself, but may serve as a useful representation
for creating specialized search programs.

\subsection{Preliminaries}
We use the same definition of trees as in
\cite{sorensen1998introduction}. That is, a tree over a set $E$ is a
partial function $t : \mathbb{N}_1^\star \rightarrow E$, with the
usual restrictions required for representing finitely branching trees
(see \cite{sorensen1998introduction}\cite{courcelle1983fundamental}
for details).

By $\dom(t)$ we denote the set of nodes in tree $t$, and by
$t(\alpha)$ we denote the label at node $\alpha$. ${\rm anc}(t,
\alpha)$ denotes the set of ancestors for node $\alpha$ in tree
$t$. By $\anc(t, \alpha)$ we denote the set of nodes that are
ancestors to $\alpha$ in $t$, and for some $\alpha \in \dom(t)$,
$t\{\alpha := t'\}$ denotes the tree obtained from $t$ by replacing
the subtree rooted at node $\alpha$ with $t'$.

The tree $e \rightarrow e_1, ..., e_n$ is the tree with root labeled
$e$ and children labeled $e_1, ..., e_n$.

\subsection{Building the process tree}
The trace semantics for TRFL can be seen in Figure
\ref{fig:tracing}. The semantics are non-deterministic when a branch
cannot be decided, and therefore describes an infinite process tree.

A C-term $\widehat{t}$ in our language fully describes a given set of
program states, and the semantics therefore describes transitions
between C-terms. Each transition is associated with a
\emph{contraction} $\kappa$, which reflects the constraint that must
be satisfied for the program to reach the given destination state.

A process tree is a tree $t$ with labels over $\mathcal{K} \times
\widehat{\mathcal{L}}$. For brevity, we write $t_\mathcal{L}(\alpha)$
for the $\widehat{\mathcal{L}}$-part of $t(\alpha)$ and
$t_\mathcal{K}(\alpha)$ for the $\mathcal{K}$-part. When building the
process tree for a given program, we start with the tree
$(\kappa_{id}, \widehat{t_0}) \rightarrow$ consisting of a single node
with the initial program state $\widehat{t_0}$ as label. Using the
trace semantics, we iteratively add child nodes, creating branches
when multiple rules apply at the same time. For a tree $t$ and a leaf
node $\alpha \in \dom(t)$, we write ${\rm drive}(t, \alpha)$ to denote
the tree obtained by exhaustively applying the tracing rules on
$t_\mathcal{L}(\alpha)$, adding the resulting constraction/state pairs
as child nodes to $\alpha$.


\begin{figure*}
  \begin{align}
    \nfrac{
      \widehat{ea_1} = \widehat{ea_2}
    }{
      |-_\Gamma \texttt{if $\widehat{ea_1}$ = $\widehat{ea_2}$ then $\widehat{t_1}$ else $\widehat{t_2}$} => <<\kappa_{id},\widehat{t_1}>>
    } \tagsc{If-Eq}
\\\nonumber\\
    \nfrac{
      \widehat{ea_1} \neq \widehat{ea_2} \quad \kappa = (\widehat{ea_1}\ \#\ \widehat{ea_2})
    }{
      |-_\Gamma \texttt{if $\widehat{ea_1}$ = $\widehat{ea_2}$ then $\widehat{t_1}$ else $\widehat{t_2}$} => <<\kappa, \widehat{t_2}>>
    } \tagsc{If-Neq-False}
\\\nonumber\\
    \nfrac{
      \widehat{ea_1} \neq \widehat{ea_2} \quad (\widehat{ea_1}\ \#\ \widehat{ea_2}) \not \in \textrm{Tauto} \quad \kappa = [\textrm{mkBind}(\widehat{ea_1}, \widehat{ea_2})]
    }{
      |-_\Gamma \texttt{if $\widehat{ea_1}$ = $\widehat{ea_2}$ then $\widehat{t_1}$ else $\widehat{t_2}$} => <<\kappa, \widehat{t_1}>>
    } \tagsc{If-Neq-True}
  \end{align}

  ~\newline

  \begin{align}
    \nfrac{
      \begin{array}{c}
        \widehat{e_0} = [\widehat{e_\alpha}, \widehat{e_\beta}] \quad \theta = \{ x_\alpha := \widehat{e_\alpha}, x_\beta := \widehat{e_\beta}, x_1 := \widehat{e_1}, ..., x_n := \widehat{e_n} \} \\
        \Gamma(\textit{gname}) =
        \begin{array}{l}
          \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
          \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{0.95cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
        \end{array}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily gname} $\widehat{e_0}$ ... $\widehat{e_n}$} => <<\kappa_{id},  t_1 / \theta>>
    } \tagsc{Case-Cons}
\\\nonumber\\
    \nfrac{
      \begin{array}{c}
        \widehat{e_0} = \widehat{ea} \quad \theta = \{ .x := \widehat{ea}, x_1' := \widehat{e_1}, ..., x_n' := \widehat{e_n} \} \\
        \Gamma(\textit{gname}) =
        \begin{array}{l}
          \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
          \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{0.95cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
        \end{array}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily gname} $\widehat{e_0}$ ... $\widehat{e_n}$} => << \kappa_{id}, t_2 / \theta>>
    } \tagsc{Case-Atom}
\\\nonumber\\
    \nfrac{
      \begin{array}{c}
        \widehat{e_0} = \widehat{Xe} \quad \theta = \{ x_\alpha := \widehat{X_{e_1}^\diamond}, x_\beta := \widehat{X_{e_2}^\diamond}, x_1 := \widehat{e_1}, ..., x_n := \widehat{e_n} \} \\
        \kappa = [\widehat{Xe} \mapsto [\widehat{X_{e_1}^\diamond}, \widehat{X_{e_2}^\diamond}]] \\
        \Gamma(\textit{gname}) =
        \begin{array}{l}
          \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
          \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{0.95cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
        \end{array}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily gname} $\widehat{e_0}$ ... $\widehat{e_n}$} => <<t_1 / \theta, \kappa>>
    } \tagsc{Case-Var-Cons}
\\\nonumber\\
    \nfrac{
      \begin{array}{c}
        \widehat{e_0} = \widehat{Xe} \quad \theta = \{ .x := \widehat{X_{a}^\diamond}, x_1' := \widehat{e_1'}, ..., x_n' := \widehat{e_n'} \} \\
        \kappa = [\widehat{Xe} \mapsto \widehat{Xa^\diamond}] \\
        \Gamma(\textit{gname}) =
        \begin{array}{l}
          \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
          \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{0.95cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
        \end{array}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily gname} $\widehat{e_0}$ ... $\widehat{e_n}$} => <<\kappa, t_2 / \theta>>
    } \tagsc{Case-Var-Atom}
  \end{align}

  ~\newline

  \begin{equation}
    \nfrac{
      \begin{array}{c}
        \Gamma(\textit{fname}) =
          \texttt{fun \textit{\rmfamily fname} $x_1$ $\ldots$ $x_n$ = $t$} \\
        \theta = \{ x_1 := \widehat{e_1}, ..., x_n := \widehat{e_n} \}
      \end{array}
    }{
      |-_\Gamma \texttt{\textit{\rmfamily fname} $\widehat{e_1}$ ... $\widehat{e_n}$} => << \kappa_{id}, t / \theta>>
    } \tagsc{Call}
  \end{equation}

  ~\newline

  \begin{equation}
    \nfrac{
      |-_\Gamma \widehat{t} => << \kappa, \widehat{t'} >>
    }{
      |-_\Gamma \texttt{let $\emptyset$ in $\widehat{t}$} => <<\kappa, \texttt{let $\emptyset$ in $\widehat{t'}$}>>
    } \tagsc{Let-NonProper}
  \end{equation}

  \begin{equation}
    \nfrac{
     L = \texttt{$\widehat{X_1}$ = $\widehat{e_1}$; $...$; $\widehat{X_n}$ = $\widehat{e_n}$}
    }{
      |-_\Gamma \texttt{let $L$ in $\widehat{t}$} => <<\kappa, \texttt{let $\emptyset$ in $\widehat{t'}$} >>
    } (n > 0) \tagsc{Let-Proper}
  \end{equation}

  \caption{Trace semantics}
  \label{fig:tracing}
\end{figure*}


\subsection{Closed process trees}
Iteratively driving the leaves of a process tree until there are no
more leaf nodes for which the trace rules apply, will not guarantee
termination. In order to ensure termination, we must employ some kind
of stop criterion to prevent our algorithm from going on indefinitely,
while still ensuring that all possible control flows are represented
in the process tree.

\begin{definition}
  For some tree $t$ and leaf node $\alpha \in \dom(t)$, we say that
  $\alpha$ is \emph{processed} if $t_\mathcal{L}(\alpha)$ is not
  proper and at least one of the following is true:
  \begin{enumerate}
    \item $t_\mathcal{L}(\alpha) = \widehat{e}$ ~~ ($\alpha$ is a terminal node), or
    \item There exists some $\beta \in \anc(t, \alpha)$ such that
      $t_\mathcal{L}(\alpha)$ is a renaming of $t_\mathcal{L}(\beta)$,
      with preservation of variable types.
  \end{enumerate}
\end{definition}
If a node is processed, the algorithm will stop driving and proceed to
processing other leaf nodes until all nodes are processed.

The above stop criterion is sound with regards to ensuring that the
resulting process tree covers all possible control flows of the
program. Since we define renaming up to preservation of variable
types, and because we do not propagate negative information, driving
two nodes $\alpha, \beta \in \dom(t)$ where $t_\mathcal{L}(\alpha)$ is
a renaming of $t_\mathcal{L}(\beta)$ and $\alpha$ is a descendent of
$\beta$, will yield isomorphic process trees, up to renaming of
variables.

Using the above stop criterion alone will not ensure that the tracing
algorithm terminates in all cases, since it will fail to stop on
infinitely increasing terms.


\section{Size-change termination analysis}

\begin{figure*}\centering
  \begin{equation}
    \nfrac{
    }{
      \texttt{'}s_1 <| \texttt{'}s_2
    } (s_1 = s_2) \tagsc{Atoms}
  \end{equation}

  \begin{equation}
    \nfrac{
    }{
      \texttt{.}x_1 <| \texttt{.}x_2
    }
    \qquad
    \nfrac{
    }{
      x_1 <| x_2
    }
    \qquad
    \nfrac{
    }{
      \texttt{.}x_1 <| x_2
    } \tagsc{Variables}
  \end{equation}

  \begin{equation}
    \nfrac{
      e_1 <| e_1'\quad e_2 <| e_2'
    }{
      \texttt{[$e_1$, $e_2$]} <| \texttt{[$e_1'$, $e_2'$]}
    }
    \qquad
    \nfrac{
      e <| e_1
    }{
      e <| \texttt{[$e_1$, $e_2$]}
    }
    \qquad
    \nfrac{
      e <| e_2
    }{
      e <| \texttt{[$e_1$, $e_2$]}
    }
    \tagsc{Cons}
  \end{equation}

  \begin{equation}
    \nfrac{
      ea_1 <| ea_1' \quad ea_2 <| ea_2' \quad t_1 <| t_1' \quad t_2 <| t_2'
    }{
      \texttt{if $ea_1$ = $ea_2$ then $t_1$ else $t_2$} <| \texttt{if $ea_1'$ = $ea_2'$ then $t_1'$ else $t_2'$}
    } \tagsc{If-A}
  \end{equation}

  \begin{equation}
    \nfrac{
      \exists t' \in \{ea_1, ea_2, t_1, t_2\}. t <| t'
    }{
      t <| \texttt{if $ea_1$ = $ea_2$ then $t_1$ else $t_2$}
    } \tagsc{If-B}
  \end{equation}

\begin{equation}
  \nfrac{
    \forall i \in \{0, \ldots, n\}. e_i <| e_i'
  }{
    h(e_0, \ldots, e_n) <| h(e_0', \ldots, e_n')
  } (h \in G \cup F)
  \qquad
  \nfrac{
    \exists i \in \{0, \ldots, n\}. e <| e_i'
  }{
    e <| h(e_0', \ldots, e_n')
  }
 \tagsc{Call}
\end{equation}

\caption{Homeomorphic embedding relation}
\label{fig:embedding}
\end{figure*}


\section{Future Work}
\subsection{Size-change termination analysis}
  The Size-Change Termination Analysis (SCTA)\cite{lee2001size} can be
  used to identify programs that terminate for all inputs, and
  size-change graphs resulting from this approach may be used to cut
  branches in a process tree, minimizing its size. We are not aware of
  any uses of SCTA in the field of inverse interpretation, but in this
  report we will investigate whether this approach is feasible.



\bibliographystyle{abbrvnat}
\bibliography{../bibliography}

\appendix
\section{TRFL Semantics}
\begin{figure*}\centering
  \begin{equation}
    \nfrac{
      ea_1/ \sigma = ea_2/\sigma \quad
      \sigma |-_\Gamma t_1 => v_1
    }{
      \sigma |-_\Gamma \texttt{if $ea_1$ = $ea_2$ then $t_1$ else $t_2$} => v_1
    }
    \qquad
    \nfrac{
      ea_1/ \sigma \neq ea_2/\sigma \quad
      \sigma |-_\Gamma t_2 => v_2
    }{
      \sigma |-_\Gamma \texttt{if $ea_1$ = $ea_2$ then $t_1$ else $t_2$} => v_2
    } \tagsc{If}
\end{equation}

\begin{equation}
\hspace{-0.7cm}
  \nfrac{
    \begin{array}{c}
      \Gamma(\textit{gname}) =
      \begin{array}{l}
        \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
        \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{1.1cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
      \end{array} \\
      e_0/\sigma = \texttt{[$v_1$, $v_2$]} \\
      \sigma\{x_\alpha |-> v_1, x_\beta |-> v_2, x_1 |-> e_1/\sigma, \ldots, x_n |-> e_n/\sigma\} |-_\Gamma t_1 => v_1
    \end{array}
  }{
    \sigma |-_\Gamma \texttt{\textit{\rmfamily gname} $e_0$ $e_1$ $\ldots$ $e_n$} => v_1
  }
\qquad
  \nfrac{
    \begin{array}{c}
      \Gamma(\textit{gname}) =
      \begin{array}{l}
        \texttt{fun \textit{\rmfamily gname} [$x_\alpha$, $x_\beta$] $x_1$ $\ldots$ $x_n$ = $t_1$} \\
        \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{1.1cm} $x_1'$ $\ldots$ $x_n'$ = $t_2$} \\
      \end{array} \\
      e_0/\sigma = \texttt{'}s \\
      \sigma\{\texttt{.}x |-> \texttt{'}s, x_1' |-> e_1/\sigma, \ldots, x_n' |-> e_n/\sigma\} |-_\Gamma t_1 => v_1
    \end{array}
  }{
    \sigma |-_\Gamma \texttt{\textit{\rmfamily gname} $e_0$ $e_1$ $\ldots$ $e_n$} => v_1
  }
  % \nfrac{
  %   \begin{array}{c}
  %     \Gamma(\textit{gname}) =
  %     \begin{array}{l}
  %       \texttt{fun \textit{\rmfamily gname} [$x_1$, $x_2$] $x_3$ $\ldots$ $x_n$ = $t_1$} \\
  %       \texttt{\ \ | \textit{\rmfamily gname}\ \texttt{.}$x$ \hspace{.7cm} $x_3'$ $\ldots$ $x_n'$ = $t_2$} \\
  %     \end{array} \\
  %     e_1/\sigma = \texttt{'$s$} \\
  %     \sigma\{\texttt{.}x |-> \texttt{'}s, x_3' |-> e_2/\sigma, \ldots, x_n' |-> e_n/\sigma\} |-_\Gamma t_2 => v_2
  %   \end{array}
  % }{
  %   \sigma |-_\Gamma \texttt{\textit{\rmfamily gname} $e_1$ $e_2$ $\ldots$ $e_n$} => v_2
  % }
  \tagsc{Call-G}
\end{equation}

\begin{equation}
  \nfrac{
    \begin{array}{c}
      \Gamma(\textit{fname}) =
        \texttt{fun \textit{\rmfamily fname} $x_1$ $x_2$ $\ldots$ $x_n$ = $t$}
        \\
      \sigma\{x_1 |-> e_1/\sigma, x_2 |-> e_2/\sigma, \ldots, x_n |-> e_n/\sigma\} |-_\Gamma t => v
    \end{array}
  }{
    \sigma |-_\Gamma \texttt{\textit{\rmfamily fname} $e_1$ $e_2$ $\ldots$ $e_n$} => v
  } \tagsc{Call-F}
\end{equation}


\caption{Operational Semantics for TSG'}
\label{fig:semantics}
\end{figure*}





\end{document}
